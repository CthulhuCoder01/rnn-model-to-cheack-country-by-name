# -*- coding: utf-8 -*-
"""Name Country Modal RNN Using Pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HS5pXychj0bGsCrvN3H5h7HPO7WIiDn4
"""
# Get file from terminal
# !wget https://download.pytorch.org/tutorial/data.zip

# !unzip *.zip

""" # This is a multiclass clasification as there are so many diffrent names"""

import os
import numpy as np
import unicodedata
import string

import torch
import torch.nn as nn

all_letters = string.ascii_letters + " .,;'"
n_letters = len(all_letters)

def unicodeToAscii(s):
  return ''.join(
      # Here we used a filtered generato expression to create an array of c fromo
      # normalised cahrated using NFD format then check is they have any non space mark if not
      #then add its value if yes then check is characted is present in all_letter 
      # then showit
      c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn'and c in all_letters
  )

all_names = []
all_country = []

for f in  os.listdir('/content/data/names'):
    fl = open("/content/data/names/"+f, "r")
    lis = fl.readlines()
    clean_lis = list(map(unicodeToAscii,lis))
    all_names.extend(clean_lis)
    country_name = f.split(".")[0]
    all_country.extend( [ country_name ]  * len(clean_lis) )

n_rows = len(all_names)

"""Now Comes One Hot Embedding to generate input for RNN model"""

# This emb is identity matrix of size n_letters x n_letters
emb = torch.eye(n_letters)
#mapping is done this way becuse maye all elemtns are unique to get range of all
#zipfunction map two array with their coresponding array to get a zip interablw with common value
mapzip = zip(np.unique(all_country), range(n_rows))
# And dict convert them into ket valu pair
mapping = dict(mapzip)

"""## Converting name into char"""

def get_data(idx):
  name = all_names[idx]
  country = all_country[idx]
  name_char_lis = np.array(list(name))
  # Search through the np array name-charlist then convert it to a column array then 
  # Find index of letters from whole letter  porpose to get numerical value
  indices = np.where(name_char_lis[..., None] == np.array(list(all_letters)))[1]
  # Now we will get country code as in form of tensor and all indices in
  # Form of numpy array in form of embeded with one hot encodin
  # print(indices)
  # Now as emb has n_letters of charaters here hot encoding based on all charaters not max
  # chereter here
  # Here mapping is country dict we created earlies with all unique country
  return emb[torch.from_numpy(indices)], torch.tensor(mapping[country])

name = "Cthulhu"
country = "Pacific"
name_char_list = np.array(list(name))

column_array = name_char_list[..., None]
row_array = name_char_list[None,...]
column_array_reshape = name_char_list.reshape(-1, 1)
row_array_reshape = name_char_list.reshape(1, -1)

print(column_array)
print(row_array)
print(column_array_reshape)
print(row_array_reshape)



"""## Here we will define an RNN """

class Net(nn.Module):

  def __init__(self, n_country, n_letters):
    super(Net, self).__init__()
    self.rnn = nn.RNN(n_letters, 2 * n_letters)
    # This is last layer multiplication for outcome with n_country instead of 1 because of
    # multilevel Nural network
    #Shape of linear modal
    self.fc = nn.Linear(2 * n_letters, n_country)

  def forward(self,x):
    out, _ = self.rnn(x)
    # Now take value from last step of rnn using out[-1,:] and give result to user
    out1 = self.fc(out[-1,:])
    return out1

n_countries = len(np.unique(all_country))
model = Net(n_country=n_countries, n_letters=n_letters)

print(model)

# Loss function i.e Cross Entropy loss function
loss_fn = nn.CrossEntropyLoss()
# Gradient Desent
#Model.parametrs() give all learnable parameters of an object wwith include weight,baises of 
# RNN and fully conected layes
optimizer = torch.optim.SGD(model.parameters(), lr= 0.005)

print(loss_fn)
print(optimizer)

num_epochs = 30
all_losses = []
for epoch in range(num_epochs):
  arr = np.arange(n_rows) # 0, 1, --- 20074
  np.random.shuffle(arr) # shuffle it
  epoch_loss = 0
  for ind in arr:
    data, target = get_data(ind) # data is indices vector in one hot form and target in tensor of country code
    output = model(data)
    # This will use cross entropy loss function to calculate loss
    loss = loss_fn(output, target)
    epoch_loss += loss.detach().numpy()
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
  all_losses.append(epoch_loss)

import matplotlib.pyplot as plt
# We can also live plot the neural network to get its value
plt.plot(all_losses)
print(all_losses)

def textToLinear(name):
  name_char_lis = np.array(list(name))
  indices = np.where(name_char_lis[..., None] == np.array(list(all_letters)))[1]
  return emb[torch.from_numpy(indices)]

# This uses tensors ans input
data, target = get_data(150)
# nameTensor = get_data(10)
output =  model(data)
predicted_labels = output.argmax()
correct_predictions = (predicted_labels == target)
# print("Predicted labels:", predicted_labels)
# print("Target labels:", target)

accuracy = torch.mean(correct_predictions.float())

print("Accuracy:", accuracy.item())

"""## Now Ploting Evaluation of results"""

torch.save(model.state_dict(), 'model.pth')
#Take 10000 values randomize them feed data to model get result 
# Cheaack how close is the result to data then give value

